{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66ui5xKeiOeb"
      },
      "source": [
        "# Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntn2_QJ-VngO",
        "outputId": "888684eb-018e-45eb-8e6d-afef9320f429"
      },
      "source": [
        "# packages\n",
        "import collections\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, Input, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "import datetime\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import io\n",
        "from skimage.transform import resize\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import imgaug.augmenters as im_aug\n",
        "%matplotlib inline\n",
        "print(\"finish loading!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish loading!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUrjajqPT2st"
      },
      "source": [
        "## Non NN Model w/o Data Aug."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js2pGwbcUIic"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3bQrToTGjSh"
      },
      "source": [
        "path_var = '/content/drive/MyDrive/data/' \n",
        "images = np.load(path_var + 'images_origin.npy') # read data\n",
        "labels = np.load(path_var + 'labels.npy')\n",
        "image_names = np.load(path_var + 'image_names.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBG0met02T9F"
      },
      "source": [
        "def print_results(results): # function for print hyperparameter value and model accuracy\n",
        "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
        "\n",
        "    means = results.cv_results_['mean_test_score']\n",
        "    stds = results.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
        "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06RuXdNA2Vew"
      },
      "source": [
        "num_img, xdim, ydim, channel = images.shape\n",
        "x_nonNN = images.reshape((num_img, xdim * ydim * channel)) # reshape to 2d array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cefPTnEvOKqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd06d35-ccf0-4ed9-f095-34bae5894e9d"
      },
      "source": [
        "x_nonNN_train, x_nonNN_valid, y_nonNN_train, y_nonNN_valid = train_test_split(x_nonNN, labels, stratify = labels) # keep the balance of the data (class weight)\n",
        "print(x_nonNN_train.shape, y_nonNN_train.shape)\n",
        "print(x_nonNN_valid.shape, y_nonNN_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(447, 196608) (447,)\n",
            "(150, 196608) (150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVjkV7Cft19O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c17c02fb-51ba-47bf-c8d7-2018b97e36c1"
      },
      "source": [
        "rfcl = RandomForestClassifier(criterion=\"entropy\")\n",
        "parameters = {\n",
        "    'n_estimators': [300, 500],\n",
        "    'max_features': [3, 5, 7],\n",
        "    'min_samples_leaf': [1, 3, 5]\n",
        "}\n",
        "\n",
        "rf_cv = RandomizedSearchCV(rfcl, parameters, verbose = 3, cv = 5)\n",
        "rf_cv.fit(x_nonNN_train, y_nonNN_train)\n",
        "\n",
        "print_results(rf_cv)\n",
        "\n",
        "y_pred = rf_cv.predict(x_nonNN_valid)\n",
        "print(\"The confusion matrix is: \")\n",
        "print(confusion_matrix(y_nonNN_valid, y_pred))\n",
        "\n",
        "precision, recall, f1, support = precision_recall_fscore_support(y_nonNN_valid, y_pred, average='macro')\n",
        "print(\"precision score: %.2f\" % (precision))\n",
        "print(\"recall score: %.2f\" % (recall))\n",
        "print(\"f1 score: %.2f\" % (f1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=5 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=5, score=0.578, total=   1.9s\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=5 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=5, score=0.522, total=   1.9s\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=5 ............\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=5, score=0.573, total=   1.9s\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=5 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=5, score=0.573, total=   1.8s\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=5 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=5, score=0.596, total=   1.8s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=5, score=0.556, total=   1.2s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=5, score=0.533, total=   1.2s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=5, score=0.562, total=   1.2s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=5, score=0.596, total=   1.2s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=5, score=0.596, total=   1.1s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=5, score=0.533, total=   1.1s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=5, score=0.544, total=   1.1s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=5, score=0.539, total=   1.1s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=5, score=0.573, total=   1.1s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=5, score=0.562, total=   1.1s\n",
            "[CV] n_estimators=500, min_samples_leaf=5, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=5, max_features=3, score=0.511, total=   1.3s\n",
            "[CV] n_estimators=500, min_samples_leaf=5, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=5, max_features=3, score=0.533, total=   1.3s\n",
            "[CV] n_estimators=500, min_samples_leaf=5, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=5, max_features=3, score=0.539, total=   1.4s\n",
            "[CV] n_estimators=500, min_samples_leaf=5, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=5, max_features=3, score=0.607, total=   1.3s\n",
            "[CV] n_estimators=500, min_samples_leaf=5, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=5, max_features=3, score=0.539, total=   1.3s\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=3, score=0.567, total=   1.5s\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=3, score=0.544, total=   1.5s\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=3, score=0.562, total=   1.5s\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=3, score=0.618, total=   1.6s\n",
            "[CV] n_estimators=500, min_samples_leaf=1, max_features=3 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=1, max_features=3, score=0.607, total=   1.5s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=5, score=0.533, total=   1.7s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=5, score=0.533, total=   1.7s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=5, score=0.551, total=   1.8s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=5, score=0.584, total=   1.7s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=5 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=5, score=0.584, total=   1.8s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=7, score=0.544, total=   2.2s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=7, score=0.511, total=   2.0s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=7, score=0.551, total=   2.0s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=7, score=0.562, total=   2.1s\n",
            "[CV] n_estimators=500, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=500, min_samples_leaf=3, max_features=7, score=0.573, total=   2.1s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=7, score=0.544, total=   1.3s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=7, score=0.533, total=   1.3s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=7, score=0.528, total=   1.3s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=7, score=0.584, total=   1.3s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=7, score=0.573, total=   1.3s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=7, score=0.567, total=   1.4s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=7, score=0.533, total=   1.4s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=7, score=0.551, total=   1.4s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=7, score=0.562, total=   1.4s\n",
            "[CV] n_estimators=300, min_samples_leaf=1, max_features=7 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=1, max_features=7, score=0.607, total=   1.4s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=3 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=3, score=0.533, total=   0.9s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=3 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=3, score=0.500, total=   1.0s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=3 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=3, score=0.539, total=   0.9s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=3 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=3, score=0.584, total=   1.0s\n",
            "[CV] n_estimators=300, min_samples_leaf=3, max_features=3 ............\n",
            "[CV]  n_estimators=300, min_samples_leaf=3, max_features=3, score=0.551, total=   0.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BEST PARAMS: {'n_estimators': 500, 'min_samples_leaf': 1, 'max_features': 3}\n",
            "\n",
            "0.568 (+/-0.049) for {'n_estimators': 500, 'min_samples_leaf': 1, 'max_features': 5}\n",
            "0.568 (+/-0.048) for {'n_estimators': 300, 'min_samples_leaf': 1, 'max_features': 5}\n",
            "0.55 (+/-0.03) for {'n_estimators': 300, 'min_samples_leaf': 3, 'max_features': 5}\n",
            "0.546 (+/-0.064) for {'n_estimators': 500, 'min_samples_leaf': 5, 'max_features': 3}\n",
            "0.58 (+/-0.056) for {'n_estimators': 500, 'min_samples_leaf': 1, 'max_features': 3}\n",
            "0.557 (+/-0.046) for {'n_estimators': 500, 'min_samples_leaf': 3, 'max_features': 5}\n",
            "0.548 (+/-0.042) for {'n_estimators': 500, 'min_samples_leaf': 3, 'max_features': 7}\n",
            "0.553 (+/-0.044) for {'n_estimators': 300, 'min_samples_leaf': 3, 'max_features': 7}\n",
            "0.564 (+/-0.049) for {'n_estimators': 300, 'min_samples_leaf': 1, 'max_features': 7}\n",
            "0.541 (+/-0.054) for {'n_estimators': 300, 'min_samples_leaf': 3, 'max_features': 3}\n",
            "The confusion matrix is: \n",
            "[[ 4 15  1  1]\n",
            " [ 1 65  1  7]\n",
            " [ 1 13  1  3]\n",
            " [ 0 28  0  9]]\n",
            "precision score: 0.50\n",
            "recall score: 0.34\n",
            "f1 score: 0.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKOUk3nDnkdL"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSi40-b8nmdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762187d3-0fa6-4644-f249-3bb04e527a81"
      },
      "source": [
        "knncl = KNeighborsClassifier(n_neighbors=30, p=2)\n",
        "# use euclidean distance\n",
        "# parameters = {\n",
        "#   'n_neighbors': [30, 35, 40],\n",
        "#  'weights': [\"uniform\", \"distance\"],\n",
        "#}\n",
        "\n",
        "#knn_cv = RandomizedSearchCV(knncl, parameters, verbose = 3, cv = 5)\n",
        "knncl.fit(x_nonNN_train, y_nonNN_train)\n",
        "\n",
        "#print_results(knncl)\n",
        "\n",
        "y_pred=knncl.predict(x_nonNN_valid)\n",
        "print(\"The confusion matrix is: \")\n",
        "print(confusion_matrix(y_nonNN_valid,y_pred))\n",
        "\n",
        "precision,recall,f1,support=precision_recall_fscore_support(y_nonNN_valid,y_pred, average='macro')\n",
        "accuracy=accuracy_score(y_nonNN_valid, y_pred)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The confusion matrix is: \n",
            "[[ 1 19  0  1]\n",
            " [ 0 71  0  3]\n",
            " [ 1 15  0  2]\n",
            " [ 0 30  0  7]]\n",
            "0.5266666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keQpZZwstqXR"
      },
      "source": [
        "## NN Model Baseline w/o Aug:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziTZOhOiuPGx"
      },
      "source": [
        "### Load data for NN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA12bvicuR1N"
      },
      "source": [
        "path_var = '/content/drive/MyDrive/project_data/' \n",
        "images = np.load(path_var + 'images_origin.npy')\n",
        "labels = np.load(path_var + 'labels.npy')\n",
        "image_names = np.load(path_var + 'image_names.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW98jqiku6Vl",
        "outputId": "bf7a5d6b-6899-4c84-890c-46bdc94795c2"
      },
      "source": [
        "print(images.shape, labels.shape, len(image_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(597, 256, 256, 3) (597,) 597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDL8gqy1u-bI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8475e1-9fc6-485b-e7cd-48c223c13bf3"
      },
      "source": [
        "print(np.min(images), np.max(images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOvAI7hvv0Qa"
      },
      "source": [
        "labels_cat = keras.utils.to_categorical(labels, 4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npk4bx3fwA-1",
        "outputId": "a5948372-d3cf-4c49-e809-d22580501414"
      },
      "source": [
        "labels_cat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5wAiU6l4A9l",
        "outputId": "a2063d14-0deb-4f6c-fb9d-0a4684610ec0"
      },
      "source": [
        "test_label = np.argmax(labels_cat,axis=-1) # change back to original\n",
        "test_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 1, 3, 3, 0, 3, 1, 1, 2, 1, 1, 3, 3, 3, 2, 0, 1, 1, 3, 1, 1,\n",
              "       0, 3, 1, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 3, 1, 2,\n",
              "       3, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 2, 0, 1, 3, 1, 1, 1, 1, 2, 0, 3,\n",
              "       3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 1, 0, 1, 2, 1, 2, 1, 3, 2, 1, 1, 0,\n",
              "       1, 0, 1, 3, 1, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1,\n",
              "       1, 3, 1, 1, 0, 3, 0, 1, 1, 1, 1, 3, 1, 1, 1, 1, 0, 2, 0, 2, 2, 1,\n",
              "       3, 1, 0, 2, 3, 1, 1, 3, 1, 3, 1, 3, 3, 1, 1, 1, 0, 2, 1, 1, 3, 3,\n",
              "       3, 3, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 3, 1, 0, 2, 1, 2, 1,\n",
              "       1, 0, 3, 1, 0, 0, 2, 0, 3, 0, 2, 1, 0, 0, 0, 1, 1, 2, 3, 1, 2, 1,\n",
              "       0, 1, 1, 1, 3, 1, 0, 3, 0, 3, 1, 1, 0, 2, 0, 1, 1, 3, 1, 1, 1, 1,\n",
              "       3, 1, 0, 1, 3, 1, 1, 2, 1, 1, 1, 3, 0, 1, 1, 1, 1, 1, 1, 1, 3, 1,\n",
              "       1, 1, 3, 1, 1, 0, 1, 0, 3, 1, 3, 3, 3, 1, 3, 1, 3, 1, 0, 0, 3, 1,\n",
              "       1, 1, 2, 1, 1, 3, 3, 1, 1, 3, 0, 2, 0, 1, 2, 1, 1, 3, 3, 1, 3, 1,\n",
              "       2, 3, 3, 2, 3, 0, 1, 1, 1, 1, 1, 3, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       3, 3, 2, 1, 0, 1, 2, 1, 1, 1, 3, 1, 2, 1, 1, 0, 1, 3, 3, 0, 1, 1,\n",
              "       1, 1, 3, 0, 1, 1, 3, 3, 3, 1, 1, 1, 0, 0, 1, 1, 2, 3, 1, 1, 1, 0,\n",
              "       3, 1, 3, 2, 3, 0, 1, 1, 3, 2, 3, 1, 1, 1, 3, 1, 3, 1, 3, 1, 0, 1,\n",
              "       3, 1, 1, 1, 2, 3, 1, 1, 3, 2, 2, 3, 2, 3, 3, 1, 3, 3, 3, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 2, 3, 3, 3, 3, 1, 1, 0, 3, 3, 1, 3, 1, 3, 1, 1, 1,\n",
              "       3, 1, 1, 3, 1, 1, 3, 1, 0, 3, 3, 1, 2, 1, 0, 1, 1, 2, 2, 2, 1, 1,\n",
              "       2, 3, 1, 2, 2, 1, 3, 1, 1, 1, 0, 1, 1, 0, 1, 1, 3, 3, 3, 3, 0, 0,\n",
              "       2, 0, 2, 2, 3, 2, 3, 1, 1, 1, 1, 3, 3, 2, 2, 1, 0, 3, 1, 1, 1, 2,\n",
              "       0, 0, 1, 0, 3, 2, 1, 1, 0, 2, 1, 1, 2, 1, 3, 0, 2, 3, 1, 1, 1, 1,\n",
              "       3, 1, 0, 3, 1, 1, 3, 0, 3, 3, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1,\n",
              "       2, 1, 1, 1, 3, 3, 1, 3, 0, 1, 1, 1, 3, 1, 3, 1, 3, 2, 0, 3, 1, 3,\n",
              "       1, 3, 0, 1, 3, 1, 1, 2, 0, 2, 1, 3, 3, 1, 1, 2, 1, 0, 0, 1, 1, 1,\n",
              "       3, 2, 3, 0, 1, 3, 3, 1, 1, 3, 1, 1, 1, 1, 0, 1, 2, 1, 3, 0, 0, 3,\n",
              "       1, 1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm0z2hGywDFl"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(images, labels.astype(int), test_size=0.2, random_state=42, stratify=labels.astype(int))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L1di6qOyxEP",
        "outputId": "f9688800-d3e3-4245-c37a-339ddd7be66d"
      },
      "source": [
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(477, 256, 256, 3) (120, 256, 256, 3) (477,) (120,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v93AHY87y2a2"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 4)\n",
        "y_test = keras.utils.to_categorical(y_test, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKNzJ73xSiDf"
      },
      "source": [
        "def to_categorical(target):\n",
        "  target = keras.utils.to_categorical(y_train, 4)\n",
        "  return target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYjAV9nwzYMO",
        "outputId": "1fa60a23-e160-45ae-b67c-65665f6c6b51"
      },
      "source": [
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(477, 4) (120, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsRXCpm-TBDR"
      },
      "source": [
        "### VGG16:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHq7qYnEzbQn",
        "outputId": "9b7223ca-6c6d-42a5-be1b-f5404896fb65"
      },
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_vgg_pre = Model(base_model.input,x)\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "model_vgg_pre.compile(optimizer = keras.optimizers.Adam(learning_rate=0.0000001), loss = 'categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "model_vgg_pre.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               16777728  \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 31,494,468\n",
            "Trainable params: 16,779,780\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5lWmGiW1NRZ",
        "outputId": "f6f4bd6a-1909-45e8-a18e-6193b9756126"
      },
      "source": [
        "history_vgg_pre = model_vgg_pre.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20, batch_size=4, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "120/120 - 7s - loss: 1.4326 - categorical_accuracy: 0.2495 - val_loss: 1.3771 - val_categorical_accuracy: 0.2500\n",
            "Epoch 2/20\n",
            "120/120 - 4s - loss: 1.3384 - categorical_accuracy: 0.2495 - val_loss: 1.3058 - val_categorical_accuracy: 0.2500\n",
            "Epoch 3/20\n",
            "120/120 - 4s - loss: 1.2841 - categorical_accuracy: 0.4486 - val_loss: 1.2653 - val_categorical_accuracy: 0.4917\n",
            "Epoch 4/20\n",
            "120/120 - 4s - loss: 1.2540 - categorical_accuracy: 0.4927 - val_loss: 1.2445 - val_categorical_accuracy: 0.4917\n",
            "Epoch 5/20\n",
            "120/120 - 4s - loss: 1.2387 - categorical_accuracy: 0.4927 - val_loss: 1.2338 - val_categorical_accuracy: 0.4917\n",
            "Epoch 6/20\n",
            "120/120 - 4s - loss: 1.2314 - categorical_accuracy: 0.4927 - val_loss: 1.2292 - val_categorical_accuracy: 0.4917\n",
            "Epoch 7/20\n",
            "120/120 - 4s - loss: 1.2273 - categorical_accuracy: 0.4927 - val_loss: 1.2264 - val_categorical_accuracy: 0.4917\n",
            "Epoch 8/20\n",
            "120/120 - 4s - loss: 1.2253 - categorical_accuracy: 0.4927 - val_loss: 1.2248 - val_categorical_accuracy: 0.4917\n",
            "Epoch 9/20\n",
            "120/120 - 4s - loss: 1.2246 - categorical_accuracy: 0.4927 - val_loss: 1.2245 - val_categorical_accuracy: 0.4917\n",
            "Epoch 10/20\n",
            "120/120 - 4s - loss: 1.2242 - categorical_accuracy: 0.4927 - val_loss: 1.2240 - val_categorical_accuracy: 0.4917\n",
            "Epoch 11/20\n",
            "120/120 - 4s - loss: 1.2239 - categorical_accuracy: 0.4927 - val_loss: 1.2237 - val_categorical_accuracy: 0.4917\n",
            "Epoch 12/20\n",
            "120/120 - 4s - loss: 1.2239 - categorical_accuracy: 0.4927 - val_loss: 1.2235 - val_categorical_accuracy: 0.4917\n",
            "Epoch 13/20\n",
            "120/120 - 4s - loss: 1.2234 - categorical_accuracy: 0.4927 - val_loss: 1.2234 - val_categorical_accuracy: 0.4917\n",
            "Epoch 14/20\n",
            "120/120 - 4s - loss: 1.2235 - categorical_accuracy: 0.4927 - val_loss: 1.2233 - val_categorical_accuracy: 0.4917\n",
            "Epoch 15/20\n",
            "120/120 - 4s - loss: 1.2235 - categorical_accuracy: 0.4927 - val_loss: 1.2232 - val_categorical_accuracy: 0.4917\n",
            "Epoch 16/20\n",
            "120/120 - 4s - loss: 1.2238 - categorical_accuracy: 0.4927 - val_loss: 1.2232 - val_categorical_accuracy: 0.4917\n",
            "Epoch 17/20\n",
            "120/120 - 4s - loss: 1.2234 - categorical_accuracy: 0.4927 - val_loss: 1.2232 - val_categorical_accuracy: 0.4917\n",
            "Epoch 18/20\n",
            "120/120 - 4s - loss: 1.2236 - categorical_accuracy: 0.4927 - val_loss: 1.2231 - val_categorical_accuracy: 0.4917\n",
            "Epoch 19/20\n",
            "120/120 - 4s - loss: 1.2233 - categorical_accuracy: 0.4927 - val_loss: 1.2232 - val_categorical_accuracy: 0.4917\n",
            "Epoch 20/20\n",
            "120/120 - 4s - loss: 1.2234 - categorical_accuracy: 0.4927 - val_loss: 1.2232 - val_categorical_accuracy: 0.4917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ_ZrMtd3b_I",
        "outputId": "7ab5a25f-b5ca-434e-a14c-d9aa61aab631"
      },
      "source": [
        "model_vgg_pre.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 141ms/step - loss: 1.2232 - categorical_accuracy: 0.4917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2231930494308472, 0.49166667461395264]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR9J_TKKS3TL"
      },
      "source": [
        "def inverse_categorical(target):\n",
        "  target = np.argmax(pred,axis=-1)\n",
        "  return target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkbnp6FO3iEf"
      },
      "source": [
        "pred = model_vgg_pre.predict(x_test)\n",
        "y_true = np.argmax(y_test, axis = -1)\n",
        "pred = np.argmax(pred,axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "xgsDbEaG5FF_",
        "outputId": "ca1c163c-5363-4533-92df-b2111d6da718"
      },
      "source": [
        "cm = confusion_matrix(y_true, pred)\n",
        "import itertools\n",
        "# note - this confusion matrix code was taken from https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "def plot_confusion_matrix(cm, classes, title='VGG 16 Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    print(\"Confusion matrix of test data\")\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "plot_confusion_matrix(cm,['Cofield','Depuy','Tornier','Zimmer'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix of test data\n",
            "[[ 0 17  0  0]\n",
            " [ 0 59  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0 30  0  0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X8S6FIQTD65"
      },
      "source": [
        "### ResNet50:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Icgxv19hS9hR",
        "outputId": "46bd72ad-4cc6-4990-f6d5-52cda3820cb2"
      },
      "source": [
        "# reference: https://zhuanlan.zhihu.com/p/54289848\n",
        "base_model_resnet = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(256, 256, 3), pooling=\"avg\")\n",
        "\n",
        "output = base_model_resnet.output\n",
        "for layer in base_model_resnet.layers:\n",
        "  layer.trainable = False\n",
        "y = Dense(4, activation='softmax')(output)\n",
        "model_resnet_pre = Model(base_model_resnet.input,y)\n",
        "\n",
        "model_resnet_pre.compile(optimizer = keras.optimizers.Adam(learning_rate=0.00001), loss = 'categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "model_resnet_pre.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 4)            8196        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,595,908\n",
            "Trainable params: 8,196\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj45TB1_TtoN",
        "outputId": "368a3a2b-7e2e-454b-d697-8ea9ffd7cd62"
      },
      "source": [
        "history_resnet_pre = model_resnet_pre.fit(x_train, y_train, validation_split=0.15, epochs=25, batch_size=4, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "102/102 - 7s - loss: 2.0840 - categorical_accuracy: 0.1210 - val_loss: 1.9153 - val_categorical_accuracy: 0.1111\n",
            "Epoch 2/25\n",
            "102/102 - 2s - loss: 1.8710 - categorical_accuracy: 0.1210 - val_loss: 1.7306 - val_categorical_accuracy: 0.1111\n",
            "Epoch 3/25\n",
            "102/102 - 2s - loss: 1.6965 - categorical_accuracy: 0.1210 - val_loss: 1.5831 - val_categorical_accuracy: 0.1111\n",
            "Epoch 4/25\n",
            "102/102 - 2s - loss: 1.5524 - categorical_accuracy: 0.1210 - val_loss: 1.4678 - val_categorical_accuracy: 0.1111\n",
            "Epoch 5/25\n",
            "102/102 - 2s - loss: 1.4430 - categorical_accuracy: 0.1210 - val_loss: 1.3833 - val_categorical_accuracy: 0.1111\n",
            "Epoch 6/25\n",
            "102/102 - 2s - loss: 1.3638 - categorical_accuracy: 0.2568 - val_loss: 1.3255 - val_categorical_accuracy: 0.4583\n",
            "Epoch 7/25\n",
            "102/102 - 2s - loss: 1.3095 - categorical_accuracy: 0.4988 - val_loss: 1.2894 - val_categorical_accuracy: 0.4583\n",
            "Epoch 8/25\n",
            "102/102 - 2s - loss: 1.2736 - categorical_accuracy: 0.4988 - val_loss: 1.2662 - val_categorical_accuracy: 0.4583\n",
            "Epoch 9/25\n",
            "102/102 - 2s - loss: 1.2519 - categorical_accuracy: 0.4988 - val_loss: 1.2542 - val_categorical_accuracy: 0.4583\n",
            "Epoch 10/25\n",
            "102/102 - 2s - loss: 1.2390 - categorical_accuracy: 0.4988 - val_loss: 1.2466 - val_categorical_accuracy: 0.4583\n",
            "Epoch 11/25\n",
            "102/102 - 2s - loss: 1.2317 - categorical_accuracy: 0.4988 - val_loss: 1.2426 - val_categorical_accuracy: 0.4583\n",
            "Epoch 12/25\n",
            "102/102 - 2s - loss: 1.2274 - categorical_accuracy: 0.4988 - val_loss: 1.2401 - val_categorical_accuracy: 0.4583\n",
            "Epoch 13/25\n",
            "102/102 - 2s - loss: 1.2251 - categorical_accuracy: 0.4988 - val_loss: 1.2391 - val_categorical_accuracy: 0.4583\n",
            "Epoch 14/25\n",
            "102/102 - 2s - loss: 1.2235 - categorical_accuracy: 0.4988 - val_loss: 1.2382 - val_categorical_accuracy: 0.4583\n",
            "Epoch 15/25\n",
            "102/102 - 2s - loss: 1.2231 - categorical_accuracy: 0.4988 - val_loss: 1.2374 - val_categorical_accuracy: 0.4583\n",
            "Epoch 16/25\n",
            "102/102 - 2s - loss: 1.2226 - categorical_accuracy: 0.4988 - val_loss: 1.2365 - val_categorical_accuracy: 0.4583\n",
            "Epoch 17/25\n",
            "102/102 - 2s - loss: 1.2223 - categorical_accuracy: 0.4988 - val_loss: 1.2362 - val_categorical_accuracy: 0.4583\n",
            "Epoch 18/25\n",
            "102/102 - 2s - loss: 1.2218 - categorical_accuracy: 0.4988 - val_loss: 1.2364 - val_categorical_accuracy: 0.4583\n",
            "Epoch 19/25\n",
            "102/102 - 2s - loss: 1.2222 - categorical_accuracy: 0.4988 - val_loss: 1.2362 - val_categorical_accuracy: 0.4583\n",
            "Epoch 20/25\n",
            "102/102 - 2s - loss: 1.2215 - categorical_accuracy: 0.4988 - val_loss: 1.2356 - val_categorical_accuracy: 0.4583\n",
            "Epoch 21/25\n",
            "102/102 - 2s - loss: 1.2218 - categorical_accuracy: 0.4988 - val_loss: 1.2358 - val_categorical_accuracy: 0.4583\n",
            "Epoch 22/25\n",
            "102/102 - 2s - loss: 1.2215 - categorical_accuracy: 0.4988 - val_loss: 1.2359 - val_categorical_accuracy: 0.4583\n",
            "Epoch 23/25\n",
            "102/102 - 2s - loss: 1.2215 - categorical_accuracy: 0.4988 - val_loss: 1.2359 - val_categorical_accuracy: 0.4583\n",
            "Epoch 24/25\n",
            "102/102 - 2s - loss: 1.2218 - categorical_accuracy: 0.4988 - val_loss: 1.2359 - val_categorical_accuracy: 0.4583\n",
            "Epoch 25/25\n",
            "102/102 - 2s - loss: 1.2221 - categorical_accuracy: 0.4988 - val_loss: 1.2354 - val_categorical_accuracy: 0.4583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFJ5-AZMaFgm",
        "outputId": "3f9c38eb-9c0b-46d9-c7d9-61e1290dcade"
      },
      "source": [
        "model_resnet_pre.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 3s 329ms/step - loss: 1.2236 - categorical_accuracy: 0.4917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2236008644104004, 0.49166667461395264]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMbbe0EkaJgx"
      },
      "source": [
        "pred = model_resnet_pre.predict(x_test)\n",
        "y_true = inverse_categorical(y_test)\n",
        "pred = inverse_categorical(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFrCFoDQalih",
        "outputId": "cecfb228-520f-4c6a-fe44-1012a936bb6e"
      },
      "source": [
        "cm_res = confusion_matrix(y_true, pred)\n",
        "print(cm_res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0 17  0  0]\n",
            " [ 0 59  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0 30  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "UTP6sknQawRx",
        "outputId": "61fc7cba-160f-48ed-cb37-85db40cd5080"
      },
      "source": [
        "#cm_res = confusion_matrix(y_true, pred)\n",
        "import itertools\n",
        "# note - this confusion matrix code was taken from https://deeplizard.com/learn/video/km7pxKy4UHU\n",
        "def plot_confusion_matrix(cm, classes, title='ResNet50 Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    print(\"Confusion matrix of test data\")\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "plot_confusion_matrix(cm_res,['Cofield','Depuy','Tornier','Zimmer'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix of test data\n",
            "[[ 0 17  0  0]\n",
            " [ 0 59  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0 30  0  0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEmCAYAAADmw8JdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxd8/3H8dd7JiuJJcSSSSIhhARBEns1iJ3EHnvsS4WqKqr9KUqrVQ0tqrRK1L4VVTtBFFnssVRIUllUEkJCiEw+vz++34ljzMy9d+bOPeden2ce95F7zj333M+ZM/O53+18j8wM55xz+alKOwDnnCsnnjSdc64AnjSdc64AnjSdc64AnjSdc64AnjSdc64AnjRdWZN0kqT/SVooaZUW7GehpLWLGVupSTpU0iNpx1HpPGmWkKRpkhbFP9APJF0vqVML93mkJJN0Zr31MyQNyeP9veL72yTWDZG0NMZZ9xiZeL2LpHskfSZpuqRDcnzGepLukDRX0ieSXpV0uqTqZhxycr9tgd8DO5tZJzOb19x9xfe/15J4GhLP+WJJq9Zb/1L8uffKYx/fOkcNMbObzGznlkXscvGkWXp7mVknYBNgU+CnRdjnR8CZkjoXYV91ZsVEUve4IfHalcBiYHXgUOBPkvo3tBNJ6wAvAO8DG5nZisABwCCgpfGuDnQAJrdwP61tKnBw3YKkjYDlivkBuRKqKx5Pmikxsw+AhwnJEwBJW0r6t6T5kl5JlhRjifI9SQskTZV0aGJ3bwLPAac39FmSqiSdLeldSfMk3S6pS3z56fj//Fii3KqpuCUtD+wH/J+ZLTSzccB9wOGNvOV84N9mdrqZzY7H/raZHWJm8+M+h0maHI97rKQNEp83TdIZsXT6iaTbJHWQtB7wdiL2JxopNY+VdGx83kfSU3E/cyXdltjOJPWJz1eUNEbSnFiS/rmkqsR5GCfpd5I+judit6Z+ZsCNwBGJ5ZHAmHo/1z1i6fNTSe9LOi/x8rfOUYzjWUmjJc0DzquLLe5v63iMPeLygBjv+jlidbmYmT9K9ACmAUPj8+7Aa8DlcbkGmAfsTvgy2ykudwWWBz4F+sZt1wT6x+dHAuMIyfdjoEtcPwMYEp//EHg+fmZ74M/ALfG1XoABbRJxDiGUJP9HKCWNBpaPr20KfF7vuM4A7m/kmD8AjmriZ7Ie8Fk83rbAmcAUoF3iZzYe6AZ0IXxBnNhQ7I0cy1jg2Pj8FuBn8efbAdg2sZ0BfeLzMcC9hJJwL+A/wDGJn/dXwHFANXASMAtQU+eckOA3iO+ZAawVP7NX4me+UYxt4/iz37uJ4zoSWAKcArQBOtb9LiS2uQh4Ir72GjAq7b+BSnh4SbP0/iFpAaG6+iHwi7j+MOBfZvYvM1tqZo8CEwlJFGApsKGkjmY228y+USU1s5eBR4GzGvjME4GfmdkMM/sSOA/Yv4kq3VuEJLwmsAMwkNB2CNCJkMCTPqHxqvYqwOxGXgMYATxgZo+a2VfA7wh/5FsntvmDmc0ys4+A+0mUzgv0FSFZdTOzLyyUkr8htrMeBPzUzBaY2TTgUr5Zkp5uZteaWS1wA+HntHqOz64rbe5ESPwzky+a2Vgzey2e+1cJCf77OfY5y8z+aGZLzGxRA6+fB6xI+NKZSWhWcS3kSbP09jazzoSSxfpAXQfBWsABsYo6X9J8YFtgTTP7jJBcTgRmS3qgkWrWucBJkur/Aa8F3JPY75tALY38oZvZB2b2RvwDnkoo/e0XX14IrFDvLSsACxo53nmEpNKYbsD0xGcvJXyh1CS2+SDx/HNC4m6OMwEB42NzwNENbLMqocQ7PbFuemPxmNnn8WmumG4EDiGUBsfUf1HSFpKejE0CnxDO9ar1t6vn/aZejF9C1wMbApdaLH66lvGkmRIze4rwC/27uOp94EYzWynxWN7MLo7bP2xmOxES0FvAtQ3s8y3gbkIVNOl9YLd6++5gZjMJ1b6c4fL178p/gDaS1k28PoDGO2Me4+uE25BZhKQOgCQBPahXEsvTZ/H/ZCfLGnVP4pfBcWbWDTgBuKquHTNhLl+XSOv0bGY8y5jZdEJTx+6Ec1TfzYS24R4WOsuuJiR4aPwcNXnuJNUQajJ/Ay6V1L4Zobt6PGmm6zJgJ0kDgL8De0naRVJ17OwYIqm7pNUlDY+dMF8SSntLG9nn+cBRwEqJdVcDF0laC0BSV0nD42tz4r6WjVGUtL2ktRT0AC4mtPERS713AxdIWl7SNsBwQkmqIb8AtpZ0iaQ14v77SPq7pJWA24E9JO2oMITox/EY/53nz3AZM5tDSG6HxZ/h0cA6ieM6QFL3uPgxIeksrbeP2hjTRZI6x5/Z6YTz01LHADvEn2F9nYGPzOwLSZsTSqV1vnWOcolfPtcDf42fOxv4ZTPjdgmeNFMU/8jHAOea2fuE5HMO4Y/kfeAnhHNURfjDnUUYXvR9QgdEQ/ucSkhgyydWX04oxTwS21OfB7aI239O6DB4NlbftyR09vybUHL7N6ET4dTE/n5AaHf8kND2dlL9NtZEPO8CWxE6MybHquddhPbaBWb2NqE994+EUt5ehGFZi5v+6TXqOMLPbR7Qn28m38HAC5IWxp/HD63hsZmnEI79PUIn283Adc2MZxkze9fMJjby8g8IX0QLCM0styfe19A5yuVUYDXCKAcjfJEeJel7LToIF3r8nHPO5cdLms45VwBPms45VwBPms45VwBPms45VwC/yD9h1VVXtbXW6pV2GEWz4MslaYdQVJ3b+69r1r344qS5Zta1mPusXmEtsyUNXfD0TbZozsNmtmsxP7sh/luYsNZavXj2hcZGhJSfZ96Zk3YIRfW9dYv6t+haQce2mp57q8LYkkW073tgzu2+ePnKXFdQFYUnTedcxgmUnZZET5rOuWwTUNWi+aqLypOmcy77pNzblIgnTedcxnn13DnnCuMlTeecy5PkbZrOOVcQr54751wBvHrunHP58o4g55zLn4/TdM65QnhJ0znnClPlbZrOOZcf4SVN55wriPeeO+dcvnxwu3POFcar5845lycpU9Xz7KTv74hHHn6Ijfv3pf/6fbjktxenHU7BLv3ZDzlg234cN2y7ZesuOv04Ttxne07cZ3sOHzqQE/fZPsUIW6bcz099FXM8qsr9KBEvaZZQbW0tp516Mg88+Cg13buz7ZaD2XPPYWzQr1/aoeVtp30OYtihx/Dbs0ctW/ez31+77Pmff3Muy3deIY3QWqwSzk9S5RxPtto0vaRZQhPGj2eddfrQe+21adeuHQeMOIh/3n9v2mEVZONBW9F5xZUafM3MeOrh+9h+931LHFVxVML5Saqo46mrojf1KBFPmiU0a9ZMunfvsWy5pqY7M2fOTDGi4npt0vOsvEpXanqtnXYozVJp56dijqdunGZGquclTZqS1pB0q6R3JU2S9C9J6zWx/SWSJsf/T5R0RI79nyfpjAbW95L0ejGOwTVu7AN3s/3u+6Qdhqs4ylTSLFmbpiQB9wA3mNlBcd0AYHXgP4287Xigi5nVlibK1tWtWw0zZry/bHnmzBnU1NSkGFHx1C5ZwrjHHuDKOx5LO5Rmq7TzU1HH8x3tPd8e+MrMrq5bYWavAONiSfJ1Sa9JGgEg6T6gEzBJ0ohkKVLSOpIeiqXVZyStX//DJA2U9IqkV4CTS3KEOQwaPJgpU95h2tSpLF68mDtuu5U99hyWdlhF8eJzT9Oj97p0XaNb2qE0W6Wdn4o6nqrq3I8SKWXv+YbApAbW7wtsAgwAVgUmSHrazIZJWmhmm0Coeifecw1wopm9I2kL4Cpgh3r7/RswysyelnRJY0FJOp5QoqVHz57NO7I8tWnThtGXX8Fee+xCbW0tI488mn79+7fqZxbbr844gVfHP8sn8z/ikO0HcPioM9ltv0MZ++A9ZV81r4Tzk1Qxx6NszXIkMyvNB0mnAr3N7Ef11o8GXjOz6+LyjcAdZnZfTJqd4vrzgIXA1cAc4O3Ebtqb2QaJbf4CvGpmPeN7NwZuNrMNm4px4MBB9uwLE1t+sBnxzDtz0g6hqL63bte0Q3A5dGyrSWY2qJj7rFq5l7Xf/v9ybvfFPccW/bMbUsqS5mRg/yLspwqYX1cCdc5VPn1H2zSfANrH6jCwrAQ4HxghqVpSV2A7YHxjOzGzT4Gpkg6I+1DsUEpuMx+YL2nbuOrQ4h6Kc65UQu1cOR/57UvTYt/Jy5ImxnVdJD0q6Z34/8pN7aNkSdNCO8A+wNA45Ggy8GvgZuBV4BVCYj3TzD7IsbtDgWNiJ89kYHgD2xwFXCnpZcJIL+dcWRJS7kcBtjezTRJV+bOBx81sXeDxuNyokl5GaWazgAMbeOkn8VF/+06J5+clnk8Fdm1g++Q2kwidS3XObE7Mzrn0tXL1fDgwJD6/ARgLnNXYxtnpknLOuUbkWdJcVdLExOP4BnZlwCNxuGLd66ub2ez4/APC2PFG+YQdzrlsi22aeZibR+/5tmY2U9JqwKOS3kq+aGYmqckhRV7SdM5lmorYpmlmM+P/HxKuUNwc+J+kNQHi/x82tQ9Pms65zCtG0pS0vKTOdc+BnYHXgfuAkXGzkUCTU0F59dw5l3lF6ghaHbgn7qsN4YKXhyRNAG6XdAwwnYY7q5fxpOmcy7xiJE0ze49vjqipWz8P2DHf/XjSdM5lW/4dQSXhSdM5l2l1HUFZ4UnTOZd5njSdc64Q2cmZnjSdcxknqKrKzuhIT5rOuczz6rlzzuXJO4Kcc65Q2cmZnjSdcxknr54751xBvCPIOecKkZ2CpidN51z2efXcOefy1Ix7ALUqT5rOuczzNk1XEsMOOT/tEIrq4wlXpB2CS0t2CpqeNJ1z2efVc+ecy5eP03TOufwJUeWTEDvnXP4yVND0pOmcyz6vnjvnXL7kJU3nnMubwNs0nXOuEJ40nXMuX149d865/AnvCHLOuQJka8KO7FwF75xzjaiqUs5HPiRVS3pJ0j/jcm9JL0iaIuk2Se1yxtLCY3HOudYV2zRzPfL0Q+DNxPJvgNFm1gf4GDgm1w48aTrnMq2uTTPXI+d+pO7AHsBf4rKAHYA74yY3AHvn2o+3aTrnMq9ITZqXAWcCnePyKsB8M1sSl2cANbl24iVN51zm5VnSXFXSxMTj+MT79wQ+NLNJLY3FS5rOuWxT3oPb55rZoEZe2wYYJml3oAOwAnA5sJKkNrG02R2YmetDvKTpnMu00KbZso4gM/upmXU3s17AQcATZnYo8CSwf9xsJHBvrng8aZbYIw8/xMb9+9J//T5c8tuL0w6nWd564Hwm3H4Oz996NuNuOhOAjdarYewNP2bC7edw52Un0Hn5DilH2TyVcH6SKuN4clfNWzCO8yzgdElTCG2cf831Bq+el1BtbS2nnXoyDzz4KDXdu7PtloPZc89hbNCvX9qhFWzX4y9n3vzPli3/6dxDOHv0PYybNIUjhm/Jj0buyAVXPZBihIWrpPMDlXU8xRzbbmZjgbHx+XvA5oW830uaJTRh/HjWWacPvddem3bt2nHAiIP45/05awNloU/P1Rg3aQoATzz/FnvvuEnKERWu0s5PxRyPije4vRg8aZbQrFkz6d69x7LlmpruzJyZs905c8yM+68axbM3ncnR+24DwJvvzWavIRsDsO9Om9F99ZXTDLFZKuX81KmU4ynWOM1iSaV6LqkWeA1oCywBxhBG5S9NIx5XmB2PGs2sOZ/QdeVO/PPqUbw97QNOOO8mLj1zf84+blceeOo1Fn9Vm3aYroJk6drztNo0F5nZJgCSVgNuJgwB+EVK8ZREt241zJjx/rLlmTNnUFOTcyxt5sya8wkAcz5eyH1PvMrg/r247MbH2esHVwKhqr7b9/qnGWKzVMr5qVNJx5OhnJl+9dzMPgSOB0YpqJZ0iaQJkl6VdAKApCGSnpb0gKS3JV0tqSq+trBuf5L2l3S9pM6SpkpqG9evkFxOw6DBg5ky5R2mTZ3K4sWLueO2W9ljz2FphdMsy3VoR6fl2i97PnSr9Zn87iy6rtwJCCWCs4/bhWvvHJdmmM1SCecnqWKOJ2NtmpnoPTez9yRVA6sBw4FPzGywpPbAs5IeiZtuDvQDpgMPAfvy9XWj9fe5QNJYwrWm/yCMzbrbzL5q1YNpQps2bRh9+RXstccu1NbWMvLIo+nXv7xKZKut0pnbfn8cAG2qq7ntwYk8+u83OfngIZwwYjsA7n3iZcbc+3yaYTZLJZyfpEo5HmVsajiZWek/VFpoZp3qrZsP9AWuBDYGPo8vrQicACwGLjCz7eL2RwMbm9lpyf1J2h/Y08yOlLQNcKaZDZf0HHCcmb1e73OPJ5R06dGz58D/vDu9lY669FYePCrtEIrq4wlXpB2Cy6FjW01q4qqcZlmh5wY2+CfX5dzuiVO3LvpnNyQTJU1JawO1wIeEzrJTzOzhetsMAepneKv3P4RLpMJKs2cl9Yrvra6fMOM21wDXAAwcOKj03yDOuZyqMlTSTL1NU1JX4GrgCgvF3oeBkxJtketJWj5uvnmcNLQKGAHUNZz9T9IGcf0+9T5iDKGj6W+tfSzOudZRxPk0WyytkmZHSS/z9ZCjG4Hfx9f+AvQCXozz3c3h6znuJgBXAH0I14zeE9efDfwzbjsRSFb9bwIuBG5ppWNxzrUiCarL4W6Ukv7It6vDy5jZqc39UDOrbuK1pcA58ZGMB+BTM9uzgffcSSMdQsC2wJ1mNr+58Trn0pWljqCmSpoTSxZFK4mJfzdg97Rjcc41X4ZyZuNJ08xuSC5LWs7MPm9s+9aWvMi+gPec0irBOOdKRoRhR1mRsyNI0laS3gDeissDJF3V6pE55xyARHVV7kep5NN7fhmwCzAPwMxeAbZrzaCccy6p7HrPzez9eg2xPhuDc64kRLbGaeaTNN+XtDVgcexk/fsGO+dcq8pQzsyren4icDLh1pazgE3isnPOlURZzadpZnOBQ0sQi3POfUvWBrfn03u+tqT7Jc2R9KGke+O14s45VxLK41Eq+VTPbwZuB9YEugF34JckOudKKEvV83yS5nJmdqOZLYmPv5OYScg551pT6D3P/SiVpq497xKfPijpbOBWwrXoI4B/lSA255wDlXZm9lya6giaREiSddGekHjNgJ+2VlDOOZdUFhN2mFnvUgbinHMNqaueZ0VeVwRJ2pBwb57krOhjWiso55xLKouSZh1JvwCGEJLmvwhTrY0jzIjunHOtSoLqDCXNfHrP9wd2BD4ws6OAAYSbnTnnXEkUY8IOSR0kjZf0iqTJks6P63tLekHSFEm3SWrX1H7ySZqL4mzqSyStQLj5WY883uecc0VRpHGaXwI7mNkAwuXgu0raEvgNMNrM+gAfA8c0tZN8kuZESSsB1xJ61F8EnssnQuecK4ZilDQtWBgX28aHATvw9e1ybuDre5I1KJ9rz38Qn14t6SFgBTN7NXeIzjnXckL5Tg23qqTkbXquibfo/npfUjWh8NcHuBJ4F5hvZkviJjMIkxM1qqnB7Zs19ZqZvdh0/C5tY++8MO0QnGs5ke/g9rlmNqipDcysFtgk1p7vAdYvNJymSpqXNvXZhCKtc861unzaEQthZvMlPQlsBawkqU0sbXYHZjb13qYGt29f3DCdc65wojjjNCV1Bb6KCbMjsBOhE+hJwiihW4GRwL1N7Sevwe3OOZemIl0RtCZwQ2zXrAJuN7N/xhtH3irpQuAl4K9N7cSTpnMu04o1CXHswN60gfXvAZvnux9Pms65zMvStef5zNwuSYdJOjcu95SUd1Z2zrmWytItfPPplLqK0MN0cFxeQBjf5Jxzra7uFr65HqWST/V8CzPbTNJLAGb2ca5rM51zrpiKPeSoJfJJml/F3iaDZd32S1s1KueciySV190ogT8QRs6vJukiwrRwv2rVqJxzLiFLbZr5XHt+k6RJhOnhBOxtZm+2emTOORdlqKCZ1yTEPYHPgfuT68zsv60ZmHPOwdcdQVmRT5vmA3x9g7UOQG/gbaB/K8blnHOBoDpDPUH5VM83Si7H2Y9+0MjmzjlXdKK8SprfYGYvStqiNYJxzrn6yu5ulJJOTyxWAZsBs1otIuecq6eskibQOfF8CaGN867WCcc5575JFGfCjmJpMmnGQe2dzeyMEsXjnHPfVOJxmLk0dbuLNma2RNI2pQzIOefqy9KQo6Y68sfH/1+WdJ+kwyXtW/coRXCV6JGHH2Lj/n3pv34fLvntxWmHU7ALzx7FbpuvyyG7bfWt1276yxVs2Wdl5n80L4XIiqPcz099lXA8dR1BuR6lks/opw7APMI9gfYE9or/uwLV1tZy2qknc+/9D/LSq29wx6238OYbb6QdVkH22PdgRl9357fW/2/WDMaPe5I1unVPIariqITzk1RJx5OlyyibSpqrxZ7z14HX4v+T4/+vlyC2ijNh/HjWWacPvddem3bt2nHAiIP45/1N3o4kczbdfBtWWGnlb62/7KKfMeqs87LV+FSgSjg/SZVyPEJUK/ejVJpKmtVAp/jonHhe93AFmjVrJt2791i2XFPTnZkzm7zxXVl4+tF/0XWNNVl3g41yb5xhlXZ+KuZ48qial7J63lTv+Wwzu6CYHyZpFeDxuLgGUAvMicubm9niZuxzGNDPzMqzwabMfbHoc66/+vf84XofheZaT5Y6gppKmkWP0szmAZsASDoPWGhmv8v1PknV8SbvDe3zPuC+fGNI3N+45Lp1q2HGjPeXLc+cOYOampo0QimaGf+dyuz3p3PYnt8DYM4Hsxg5/Ptcd/fjrNJ19ZSjK0ylnZ9KOZ5wC9+0o/haU9XzHUsRgKQdJb0k6TVJ10lqH9dPk/QbSS8CB8Tl8yW9GLddP253pKQr4vOuku6SNCE+tonrz5N0o6RngRtLcVwNGTR4MFOmvMO0qVNZvHgxd9x2K3vsOSytcIqiT9/+PDj+Hf7x1Kv846lX6bpGN26496myS5hQeeenko6nuko5H6XSaNI0s49K8PkdgOuBEXFikDbASYnX55nZZmZ2a1yea2abAX8CGhpwfzkw2swGA/sBf0m81g8YamYHJ98g6XhJEyVNnDN3Dq2pTZs2jL78CvbaYxc22WgD9jvgQPr1L6/Jov7vtGM47oCdmT51Cntt05/7bk/tO6joKuH8JFXK8YiQqHI9ShaPmZXw4xIfHKrnBuxoZtvFdTsCJ5vZvpKmAd83s+nxtWnANmY2M04YcpGZDZV0JDDIzEZJ+pBvXhffFehLSLBmZuc3FdPAgYPs2RcmFvMwU/XK9Plph1BUA9ZaKe0QXA4d22qSmQ0q5j5799vYzhvzQM7tjhzcs+if3ZCs3/f8s3rLX8b/a2k49ipgSzP7IrlSoUGk/r6cc2UiQ02aqd/krRboJalPXD4ceKoF+3sEOKVuQdImLdiXcy4DsnYL37ST5hfAUcAdkl4j3OXy6hbs71RgkKRXJb0BnFiEGJ1zKSvGOE1JPSQ9KekNSZMl/TCu7yLpUUnvxP+/ffVGQmrVczM7L7G4aQOv92ps2cwmAkPi8+sJnUmY2VxgRI7Pcs6VFdU1sbXUEuDHcSL1zsAkSY8CRwKPm9nFks4GzgbOamwnaZc0nXOuScXqPTez2Wb2Yny+AHgTqAGGAzfEzW4A9m5qP1nvCHLOuXxLmqtKSg5/ucbMrmlkf70INdwXgNXNbHZ86QOgyUHGnjSdc9mmvC+jnJvPkCNJnQh3nzjNzD5NJmQzM0lNjsP06rlzLtOKObhdUltCwrzJzO6Oq/8nac34+prAh03tw5Omcy7zJOV85LEPAX8F3jSz3ydeug8YGZ+PBJqcP8+r5865zCvSKMxtCGPBX5P0clx3DnAxcLukY4DpwIFN7cSTpnMu0wRFmWTYzMbReP7Ne4IiT5rOuczL0tRwnjSdcxknlKGrzz1pOucyz0uazjmXpzDkKDtZ05Omcy7bBFUZGhzpSdM5l3nepumcc3kK82mmHcXXPGk65zLPS5rOOVeAcrnvuXPOpc6r5845VxAf3O6cc/mTD253zrmCZChnetKsZH97aWbaIRTVZWutlHYILgXFmuWoWDxpOueyLzs505Omcy77vCPIOecKkKHauSdN51z2edJ0zrk8Ca+eO+dc/nycpnPOFSZDOdOTpnMu6/K7r3mpeNJ0zmVehnKmJ03nXLYJr54751xhMpQ1PWk65zIvS0OOMnSPN+eca1iVcj9ykXSdpA8lvZ5Y10XSo5Leif+vnDOWlh2Kc861MuX5yO16YNd6684GHjezdYHH43KTPGk65zJPefzLxcyeBj6qt3o4cEN8fgOwd679eJumcy7TRKsOOVrdzGbH5x8Aq+d6gydN51zm5Zk0V5U0MbF8jZldk+9nmJlJslzbedJ0zmVenr3nc81sUIG7/p+kNc1stqQ1gQ9zvcHbNEvskYcfYuP+fem/fh8u+e3FaYdTsDZV4uwdevPzoetw7k7rsGe/rgCsslxbztqhNxfs2odjt+ieqdsTFKLcz099lXI8Uu5HM90HjIzPRwL35nqDJ80Sqq2t5bRTT+be+x/kpVff4I5bb+HNN95IO6yCLFlqjH5qOhc+9i4XPvYu/dfoRO8uHdl3o9V5/D/zOPehKXy+uJZtepff/Xwq4fwkVdLxFKPzXNItwHNAX0kzJB0DXAzsJOkdYGhcbpInzRKaMH4866zTh95rr027du04YMRB/PP+nF9smfNl7VIAqqtEtYQBfVdbnhdnfgrAc9PnM6DbCilG2DyVcn7qVNTxFCFrmtnBZrammbU1s+5m9lczm2dmO5rZumY21Mzq965/iyfNEpo1aybdu/dYtlxT052ZM8vvjpECfjZ0bS7Zqy9vfvgZcxYu5vOvalkam9DnL/qKlTqWX3N5pZyfOpVyPBJUSTkfpdJqv9mS9gF+UW/1xsDhwD5mtn9rfbZrXQZc9Nh7dGxbxYlb9WSNzu3TDslVuCy1kLda0jSze4B76pYlHQ8cCtxiZje11ufmIqnazGrT+Oxu3WqYMeP9ZcszZ86gpqYmjVCKYtFXS3l7zmesvUpHlmtbTZVgqcFKHdsyf9GStMMrWKWdn4o6ngxlzZJUzyWtB5xLKGX2rLv2U9KRkk8QwwEAABKjSURBVP4Rr/mcJmmUpNMlvSTpeUld4nZjJY2WNFHSm5IGS7o7Xi96YeJzDpM0XtLLkv4sqTquXyjpUkmvAFuV4pgbMmjwYKZMeYdpU6eyePFi7rjtVvbYc1ha4TRLp3bVdGwbfm3aVokNVl+eDxZ8ydtzPmOzmtCOudVaK/HqrE/TDLNZKuH8JFXO8eRzPVAFVM/rSGoL3Az82Mz+K6lXvU02BDYFOgBTgLPMbFNJo4EjgMvidovNbJCkHxKGBQwkXBL1btx2NWAEsI2ZfSXpKkLJdgywPPCCmf24gfiOB44H6NGzZ/EOvAFt2rRh9OVXsNceu1BbW8vII4+mX//+rfqZxbZixzaMHFRDlYQEk2Z8ymuzFzL70y85dovuDNtwNd6f/wXPTpufdqgFq4Tzk1QpxyPym5CjVErRWv9LYLKZ3dbI60+a2QJggaRPgPvj+tcIbaB17kusn1x36ZOk94AewLaERDohTo3fka8HqtYCdzX04fGKgWsABg4clPNqgJbadbfd2XW33Vv7Y1rNzE++5FePv/et9XM/+4qLn5iaQkTFVe7np76KOZ7vStKUNATYD9isic2+TDxfmlheyjfj+7KBbZLbCbjBzH7awGd8kVY7pnOu5b4T82nGeen+BhwRS5Kt7XFgf0mrxc/vImmtEnyuc66VteIVQQVrzZLmiYR2xj/Vu5PcLa3xYWb2hqSfA49IqgK+Ak4GprfG5znnSiTPSYZLpTWHHP0a+HUjL/8mbnM9YWLQuvf0Sjxf9pqZDUmsHwuMTSwnX7sN+FbbqZl1KjB851ymZCdrlt9lG86575RWnk+zYJ40nXOZl6Gc6UnTOZd9XtJ0zrkCKENZ05Omcy7zspMyPWk65zKu1OMwc/Gk6ZzLvCxdEeRJ0zmXeV7SdM65AnjSdM65vJV2vsxcPGk65zIta1cE+Y3VnHOuAF7SdM5lXinvNpmLJ03nXLb5OE3nnMuf8CuCnHOuMBnKmp40nXOZl6U2Te89d85lnvJ45LUfaVdJb0uaIuns5sTiSdM5l31FyJqSqoErgd2AfsDBkvoVGoonTedc5imPf3nYHJhiZu+Z2WLgVmB4wbGYWaHvqViS5lC6u1euCswt0WeVgh9PtpXqeNYys67F3KGkhwjx59IB+CKxfI2ZXZPYz/7ArmZ2bFw+HNjCzEYVEo93BCUU+2Q3RdJEMxtUqs9rbX482VbOx2Nmu6YdQ5JXz51z3xUzgR6J5e5xXUE8aTrnvismAOtK6i2pHXAQcF+hO/HqeXquyb1JWfHjybZKO56CmdkSSaOAh4Fq4Dozm1zofrwjyDnnCuDVc+ecK4AnTeecK4AnzYyS5Ocmg6QMXQTtUuF/mBkjaWtJW5nZ0kr6A62EY5Eki50Ako6VdEDaMRVL8vxIWi7NWLLOk2b2bATcJGlzM7MKKnH2yL1JtiUS5q7AwcDj6UZUHJKqEsd2EnBUvE7bNaBS/iDLXl1yNLM/A38F/ixp01jiLNvzpKAT8ISk3dOOp6UkbQocD8w2s4/iurIuRZvZUgBJ+wAbAvebWW26UWVX2f4xVqC6b/pTCKWyBcDfyrmqXledNbOFwO+Amri+bEoxDfzc3wOeAVaStBeEEmg5np86kqolrQBcDww0s//GLzvPDw3wH0rKJK0Cy/7wNgdOBS4ADiFMY3W1pM3K9A9zQOL5G4RqX5dyKcXUa8M8StIPgP3NbDQwFhgiaQ/4uupeLur9LrU1s08JTUO9JP08ftmVdS2ntfgPJEWS1gbOkbRbXPUp8KKZzTKzGcCNwGTgbkmblNMfZixNniPpLkmnAa8D/wJGxVJM2XwBSDoROBqYCFwraTihVDYL2FvSLimG1yyJL4NjgD9K+hHQkTB92ihJP43bLU0vymzypJmuL4DPCCWWHYB3CdfG/hLAzL4AXiJc9vVpalEWKE7s+hPCtb2/J/wxPgFsAGwbSzGZ/QKQ1FfSCrF0vyKwNbAPsBnwCPCgmc0F/gy8ArycXrTNJ+lYYCTwN+AI4BAz+y+wFXC+pDPSjC+r/DLKFNSr9tUARwKrAzcA/wPuAV4DpgAjgN3MbFY60eYvVuUM2J7wx/gmcImZ1UraBlgPuBD4XaziZo6kLoQEMgZYaGaLJf0BWA5YGTjMzBZJ+gnwlJmNTzHcZpPUHjiLkDC3Bw4nzGheFY95LaC9mf0nxTAzyUuaJVYvYa5kZjOBS4HZhF/cGmAo8A5hEv9DyyFhRl3isf2bUH3tAZwnqdrMnjWzvwH7AaukGGOTYo/41UA34LcxuUwhnJvjYsI8kNDmXDaTFNdvDjGzL4FFhBrAYWa2k5ktAY6TNNLMpnvCbJjPclRiiYR5KqFavoRQ5fsDcBpwIHCvmf06vSgLI6kNIRG+J+kwM7tH0nOEL+UfAj+XdGHsANoM2Ckuf9HEbksq+WVmZl9IWg1oB5xpZr+U1AO4T9J0YG3gCDN7L8WQC5L4vdsZWA24ifB7tznhSw5JhwAnEH4HXSO8el4i9UqYhxOqryOAy4EVzGyYpDWAUYQS5q/M7LPUAs5D8pji8r7AtcBRZnZfXHcjIfn8n5n9R9II4BUzeyuVoHOQtAFhDOZ8SZsAxxBKlBcAvQnV9I9jDSHz6v3enQCcDMwhtJGfS2hn3hlYhzBd2g/M7PWUwi0LnjRLQNK6wAaJRHIoofNgKKEdaS+gFlgDWEgYAjIvpXALIun7wBBCh9UjwJbAvYR22tnARcApZvZGSiE2qV5S+SGhtP8MIXGeFQezH0Foq72oXM4LfOvYliOMALjJzD6WdCXhnjqXmNlbklYFFsehR64J3qbZyiQNAHYEnpHUM7aRLQ88BXzfzHY1s6+AY4EzgEXl8ocpaVtCs0JnQqn5j4QRAPsBpwC/Aa6qS5hZHGaUSCrbEEpbOwOXAGtI+oOZvQTcTBjpUFaD8hPHdgZhXOmphBoOZnYy8DnwO0l9zGyuJ8w8mZk/WukB7EBIjj0Jf5B/InTsQBiu8hShw+FkQm95v7RjLuDY+gLPE3r2IfSMnwL8Mi6vBKwYnyvteHMcy9bAx8CNcbkt0IfQmXVdXNc+7ThbcGx3EdqSjyXUAg5LvP5boCbtOMvp4SXNViKpLWEox4OEdrABhAHeW0o6iJBgXiFUX4cCIyyjVdhGrEQoYR4HYKGndSLh+FY0s/lm9kl8LVNtQMkSb2zn25TwxbWVpF0slPzfBX4NLJa0uoXe5rIiaTDhi3qGmb1IuM/3GGB/SXXn7Uwrk/bZrPA2zVYkqRfhj2+ema0W151AuFxtrJndGde1z/ofZV11L47fqzaz9yQNJDQp/NdC+98GwN+BfSwMks40hWvHdwUujcdzEPArQmfIQzG5tolJNPPqd8zFdT8G9gROM7NXJHUkDNQfRph4ZEHWvtSyzpNmkSWSSxugK3A/oep6rJndHkugI4FtCVf63ArZK401JF4+eA7wPuFKpt8S2mevIPSQzwD+YGaPpBZkDjERVhGq4BMIHTx7EkpjSxXmyLyWcI35Y+lF2nySjieM9x1nZo/GNs3vA+ea2UuSOhA6GxekGmiZ8up5EdX7pl/OzGab2SBgMHCNpONjqWUMoWH+CYtSCjmnuqqspPUJHQlDCcl+ADCNkHh+QOg9n1qXMLPW6SOpNyz7cupgYYzotoThRKdZvMbazO4AjiIcW1mo19wwlNB22YZQDT/TzH5HGMR+uaSNzewLT5jN5yXNVhC/2bcjdACNJlRZNyW0b15gZn9MMby8KExMuzTx/3rA/oQp6w4hdGjVVdFfBAYRxv09b2YXpRf5tynMRDTazNaLbXk7E5LiWOBJ4DFCqezM1IJspnq95OsAuxMmfXlW0k6Eavh/zewShdvX3mtm76cYctnzK4KKICaOauA/hF7KAwklsl0Jw42WN7Or4uV318cB359ktYQZE+QRCnMsVkm6BPgQ2JjQq3xITJhDCfNk7kkYd3oeYWxmZijMQHQJMCIOkTqNcJXSuoRmklWAXYCXJC0ys1+kFmyB6r7Q4vPTgMOAVYEHgGcJM8sbcKik08zsstSCrSBePW8hhVsfXA2sD3QitGO+bWafmtntwB3AaZL6m9mTwPqxZzmrCbMvcDcwj9CJZcBzhFLznYTp0IZLOplwNdPPzWyGmX1lZpMsQ9fJx0sGxxDm8lxAmJX8l7GtcgyhLXYXQvvsVoQJU8pGImHuTPiS3hoYTrhM9eT4+pOE47oltUArjJc0WyBeDfNHQslrQlz3NrC7pC3M7AUze0zS04QZciAMks4khSndbgLOsXj1Ulz/IaFDayDhErxBQHfClT5PNNRrmzZJOxKS4umEK61GEi4Z7CHpETP7SNIkYEWgr5m9STi2zJM0CDjQzM6MV/LsT7gefsXYQ344oUbTMbZnjk0x3IrjbZotIOl0oNbMLpfUxsyWKMy/eBahFD83Pv6PcPXPjBTDzSlWX582s6q43NHMFsXnlxES/1FWBhPTxjGKbc3s37ET62DCFTADCD39ZxA66E4j9JRnqlmhMQrzrq5N+HIbYGbPK1ymew5hWsHLzWx2vMLpD8BQM/s4vYgrjyfNZkgMK/ojoW3y57EHU7HTZGXgJMJVQAC/N7PJqQVcAIVZ5K8ANjezeZI6WJj1ZwQwzMwOTTnEgiQ6svoSOrAWEy46+IQwOfJPzeyVNGPMV0yY9xOGdm1EuNJnqZkNl7Qhodd/MXClmc2oO3fpRVyZvE2zGRJV0XsIV8AMTPRgtonf7J8Srr0+qVwSJoCZPUiYaWm8wv186v7ovgTmS2qbteFETUkMJXqbcA15NeHyzyuBvcsoYe5C6HQ7CRhvZosJM+PPl3S7hZmJrgO6AMcq3G5kcWoBVzBPmi3zAjCO0DM70MyWxir6QYQZZRbFX+6ykkicE2FZ59DFhFu7fpW19st8xcR5J6Hj5/VyOTdx6NBlwMlmNgbYJP6+fUYYO/ulpFvil/PlwJ/MrLYcmlHKkVfPW0jhdhXHEIYWTSTMhr0/oZ2srOcljFX1u4CpwE/M7F8ph1QUktpa+Vwa2YZQuqwbe1lNmILvEjN7KLHdY8C7ZnZCSqF+Z3jSLIJ4Pe9AwrCP2cCTViG3Coi90CuY2T1px/JdlehkrGufvQD4NPaM103+3Bu4y8ympRnrd4EPOSqC2MM8Lj4qipk9Dg1PBuFKw8K9eyCMmYXQvLA1gKTDgLOB/TxhloYnTZcXT5jpS5yDB4E1Je1HuLrpwNhe60rAq+fOlRlJPQnXzr9DGAHwZroRfbd477lz5Wc2YcjUME+YpeclTefKUDmNAKg0njSdc64AXj13zrkCeNJ0zrkCeNJ0zrkCeNJ0zrkCeNJ0TZJUK+llSa9LukPSci3Y1/WS9o/P/xInPW5s2yGStm7GZ0yLE/Pmtb7eNgsL/Kzz4v2g3HeIJ02XyyIz28TMNiRMNXZi8sU4oUTBzOxYM3ujiU2GEC8VdC5LPGm6QjwD9ImlwGck3Qe8Iala0iWSJkh6VdIJEK5Xl3SFpLfjLDyr1e1I0th42wYk7SrpRUmvSHpcUi9Ccv5RLOV+T1JXSXfFz5gQZyZH0iqSHpE0WdJfgJxzfUr6h6RJ8T3H13ttdFz/uKSucd06kh6K73kmzgTvvqP82nOXl1ii3A2om45sM2BDM5saE88nZjZYUnvgWUmPEG5b3BfoB6xOuMHZdfX22xW4Ftgu7qtLvH/P1cDCxEw+NxNuwzsuXkb4MOGeP78g3H73AoVb9R6Tx+EcHT+jIzBB0l1mNg9YHphoZj+SdG7c9yjgGuBEM3tH0hbAVcAOzfgxugrgSdPl0lHSy/H5M8BfCdXm8WY2Na7fGdi4rr2ScLOydQn3fr/FzGqBWZKeaGD/WxLuSzQVwMw+aiSOoUC/xKTxK0jqFD9j3/jeByTlcz+cUyXtE5/3iLHOA5YCt8X1fwfujp+xNXBH4rPb5/EZrkJ50nS5LDKzTZIrYvL4LLmKcGfKh+ttt3sR46gCtqx/z5tC77whaQghAW9lZp9LGgt0aGRzi587v/7PwH13eZumK4aHgZMktQWQtJ6k5YGnCbcCqZa0JuGGZvU9D2wnqXd8b5e4fgHQObHdI8ApdQuS6pLY04QbptXNNL8yTVsR+DgmzPUJJd06VYRZ94n7HGdmnwJTJR0QP0OSBuT4DFfBPGm6YvgLob3yRUmvA38m1GLuIUxf9gYwBniu/hvNbA5wPKEq/ApfV4/vB/ap6wgi3AtnUOxoeoOve/HPJyTdyYRq+n9zxPoQ0EbSm4T7Hj2feO0zYPN4DDsAF8T1hwLHxPgmA8Pz+Jm4CuUTdjjnXAG8pOmccwXwpOmccwXwpOmccwXwpOmccwXwpOmccwXwpOmccwXwpOmccwX4f0qOKLzP2NGLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkWUIQcmbANJ",
        "outputId": "e56cf5b7-1d4b-4687-c41e-ef7b284859a8"
      },
      "source": [
        "output = base_model_resnet.output\n",
        "for layer in base_model_resnet.layers:\n",
        "  layer.trainable = False\n",
        "y = Dense(4, activation='softmax')(output)\n",
        "model_resnet_pre2 = Model(base_model_resnet.input,y)\n",
        "\n",
        "model_resnet_pre2.compile(optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9), loss = 'categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "model_resnet_pre2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 4)            8196        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,595,908\n",
            "Trainable params: 8,196\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uEf_q3ndjsP",
        "outputId": "0a505c11-9aa9-43d8-8eba-1ea91990c74e"
      },
      "source": [
        "history_resnet_pre2 = model_resnet_pre2.fit(x_train, y_train, validation_split=0.1, epochs=25, batch_size=4, verbose=2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "108/108 - 6s - loss: 1.7678 - categorical_accuracy: 0.3660 - val_loss: 1.6952 - val_categorical_accuracy: 0.4583\n",
            "Epoch 2/25\n",
            "108/108 - 2s - loss: 1.7886 - categorical_accuracy: 0.3730 - val_loss: 2.3216 - val_categorical_accuracy: 0.4583\n",
            "Epoch 3/25\n",
            "108/108 - 2s - loss: 1.9932 - categorical_accuracy: 0.3893 - val_loss: 2.1888 - val_categorical_accuracy: 0.4583\n",
            "Epoch 4/25\n",
            "108/108 - 2s - loss: 1.7921 - categorical_accuracy: 0.3800 - val_loss: 1.7287 - val_categorical_accuracy: 0.4583\n",
            "Epoch 5/25\n",
            "108/108 - 2s - loss: 1.7991 - categorical_accuracy: 0.3497 - val_loss: 2.6622 - val_categorical_accuracy: 0.4583\n",
            "Epoch 6/25\n",
            "108/108 - 2s - loss: 1.9448 - categorical_accuracy: 0.3800 - val_loss: 1.9296 - val_categorical_accuracy: 0.1042\n",
            "Epoch 7/25\n",
            "108/108 - 2s - loss: 1.8201 - categorical_accuracy: 0.3497 - val_loss: 1.6181 - val_categorical_accuracy: 0.3125\n",
            "Epoch 8/25\n",
            "108/108 - 2s - loss: 1.8105 - categorical_accuracy: 0.3753 - val_loss: 1.9200 - val_categorical_accuracy: 0.4583\n",
            "Epoch 9/25\n",
            "108/108 - 2s - loss: 1.6976 - categorical_accuracy: 0.3660 - val_loss: 2.7375 - val_categorical_accuracy: 0.4583\n",
            "Epoch 10/25\n",
            "108/108 - 2s - loss: 1.5711 - categorical_accuracy: 0.4079 - val_loss: 1.2463 - val_categorical_accuracy: 0.4583\n",
            "Epoch 11/25\n",
            "108/108 - 2s - loss: 1.7629 - categorical_accuracy: 0.4103 - val_loss: 2.1452 - val_categorical_accuracy: 0.4583\n",
            "Epoch 12/25\n",
            "108/108 - 2s - loss: 1.8496 - categorical_accuracy: 0.4103 - val_loss: 2.3487 - val_categorical_accuracy: 0.4583\n",
            "Epoch 13/25\n",
            "108/108 - 2s - loss: 1.6419 - categorical_accuracy: 0.3986 - val_loss: 1.9161 - val_categorical_accuracy: 0.4583\n",
            "Epoch 14/25\n",
            "108/108 - 2s - loss: 1.8785 - categorical_accuracy: 0.3357 - val_loss: 2.5798 - val_categorical_accuracy: 0.4583\n",
            "Epoch 15/25\n",
            "108/108 - 2s - loss: 1.9970 - categorical_accuracy: 0.3450 - val_loss: 1.3641 - val_categorical_accuracy: 0.4583\n",
            "Epoch 16/25\n",
            "108/108 - 2s - loss: 1.7343 - categorical_accuracy: 0.3706 - val_loss: 1.5200 - val_categorical_accuracy: 0.4583\n",
            "Epoch 17/25\n",
            "108/108 - 2s - loss: 1.8381 - categorical_accuracy: 0.3730 - val_loss: 1.8836 - val_categorical_accuracy: 0.4583\n",
            "Epoch 18/25\n",
            "108/108 - 2s - loss: 1.8897 - categorical_accuracy: 0.4289 - val_loss: 1.3450 - val_categorical_accuracy: 0.4583\n",
            "Epoch 19/25\n",
            "108/108 - 2s - loss: 1.7977 - categorical_accuracy: 0.4033 - val_loss: 1.7925 - val_categorical_accuracy: 0.4583\n",
            "Epoch 20/25\n",
            "108/108 - 2s - loss: 1.9268 - categorical_accuracy: 0.3683 - val_loss: 2.0638 - val_categorical_accuracy: 0.3125\n",
            "Epoch 21/25\n",
            "108/108 - 2s - loss: 1.8635 - categorical_accuracy: 0.3706 - val_loss: 1.8374 - val_categorical_accuracy: 0.1042\n",
            "Epoch 22/25\n",
            "108/108 - 2s - loss: 1.9558 - categorical_accuracy: 0.4009 - val_loss: 2.3401 - val_categorical_accuracy: 0.4583\n",
            "Epoch 23/25\n",
            "108/108 - 2s - loss: 1.9260 - categorical_accuracy: 0.3823 - val_loss: 2.2320 - val_categorical_accuracy: 0.4583\n",
            "Epoch 24/25\n",
            "108/108 - 2s - loss: 1.6203 - categorical_accuracy: 0.3916 - val_loss: 1.8635 - val_categorical_accuracy: 0.4583\n",
            "Epoch 25/25\n",
            "108/108 - 2s - loss: 1.6571 - categorical_accuracy: 0.3543 - val_loss: 2.1485 - val_categorical_accuracy: 0.4583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWDNzpJXey3D",
        "outputId": "40132195-9f93-4a13-d50a-0b99628edd82"
      },
      "source": [
        "model_resnet_pre.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 107ms/step - loss: 1.2236 - categorical_accuracy: 0.4917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2236008644104004, 0.49166667461395264]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu1DOb6LGJYX"
      },
      "source": [
        "### VGG from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx95BdAtG8N_",
        "outputId": "5937a840-9cac-40e2-a390-9b55a5e7676a"
      },
      "source": [
        "base_model_scratch = VGG16(weights=None, include_top=False, input_shape=(256, 256, 3))\n",
        "x = base_model_scratch.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "#x = Dense(4096, activation='relu')(x)\n",
        "prediction = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_vgg_scratch = Model(base_model_scratch.input,prediction)\n",
        "# for layer in base_model.layers:\n",
        "#   layer.trainable = False\n",
        "\n",
        "model_vgg_scratch.compile(optimizer = keras.optimizers.Adam(0.00003), loss = 'categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "model_vgg_scratch.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               16777728  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 31,494,468\n",
            "Trainable params: 31,494,468\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlM_TPrmJAOl",
        "outputId": "44a90a06-4c58-48f2-eee6-ffc66e829ca4"
      },
      "source": [
        "history_vgg_scratch = model_vgg_scratch.fit(x_train, y_train, validation_split=0.1, epochs=50, batch_size=32, verbose=2) # tried batch_size of 16, 8, 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "14/14 - 72s - loss: 1.3248 - categorical_accuracy: 0.4662 - val_loss: 1.2333 - val_categorical_accuracy: 0.4583\n",
            "Epoch 2/50\n",
            "14/14 - 13s - loss: 1.2574 - categorical_accuracy: 0.4965 - val_loss: 1.2192 - val_categorical_accuracy: 0.4583\n",
            "Epoch 3/50\n",
            "14/14 - 13s - loss: 1.2471 - categorical_accuracy: 0.4965 - val_loss: 1.2234 - val_categorical_accuracy: 0.4583\n",
            "Epoch 4/50\n",
            "14/14 - 13s - loss: 1.2420 - categorical_accuracy: 0.4965 - val_loss: 1.2501 - val_categorical_accuracy: 0.4583\n",
            "Epoch 5/50\n",
            "14/14 - 13s - loss: 1.2658 - categorical_accuracy: 0.4965 - val_loss: 1.2388 - val_categorical_accuracy: 0.4583\n",
            "Epoch 6/50\n",
            "14/14 - 13s - loss: 1.2448 - categorical_accuracy: 0.4965 - val_loss: 1.2463 - val_categorical_accuracy: 0.4583\n",
            "Epoch 7/50\n",
            "14/14 - 13s - loss: 1.2445 - categorical_accuracy: 0.4988 - val_loss: 1.2271 - val_categorical_accuracy: 0.4583\n",
            "Epoch 8/50\n",
            "14/14 - 13s - loss: 1.2238 - categorical_accuracy: 0.4988 - val_loss: 1.2055 - val_categorical_accuracy: 0.4583\n",
            "Epoch 9/50\n",
            "14/14 - 13s - loss: 1.2073 - categorical_accuracy: 0.4988 - val_loss: 1.2161 - val_categorical_accuracy: 0.4583\n",
            "Epoch 10/50\n",
            "14/14 - 13s - loss: 1.1833 - categorical_accuracy: 0.5058 - val_loss: 1.1911 - val_categorical_accuracy: 0.5208\n",
            "Epoch 11/50\n",
            "14/14 - 13s - loss: 1.1667 - categorical_accuracy: 0.5245 - val_loss: 1.2039 - val_categorical_accuracy: 0.5208\n",
            "Epoch 12/50\n",
            "14/14 - 13s - loss: 1.1795 - categorical_accuracy: 0.5408 - val_loss: 1.1876 - val_categorical_accuracy: 0.5417\n",
            "Epoch 13/50\n",
            "14/14 - 13s - loss: 1.1523 - categorical_accuracy: 0.5431 - val_loss: 1.1940 - val_categorical_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "14/14 - 13s - loss: 1.1208 - categorical_accuracy: 0.5524 - val_loss: 1.1979 - val_categorical_accuracy: 0.5208\n",
            "Epoch 15/50\n",
            "14/14 - 13s - loss: 1.1197 - categorical_accuracy: 0.5315 - val_loss: 1.1932 - val_categorical_accuracy: 0.5208\n",
            "Epoch 16/50\n",
            "14/14 - 13s - loss: 1.0864 - categorical_accuracy: 0.5548 - val_loss: 1.1747 - val_categorical_accuracy: 0.4792\n",
            "Epoch 17/50\n",
            "14/14 - 13s - loss: 1.0641 - categorical_accuracy: 0.5664 - val_loss: 1.2429 - val_categorical_accuracy: 0.5208\n",
            "Epoch 18/50\n",
            "14/14 - 13s - loss: 1.0499 - categorical_accuracy: 0.5688 - val_loss: 1.2509 - val_categorical_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "14/14 - 13s - loss: 1.0342 - categorical_accuracy: 0.5851 - val_loss: 1.2768 - val_categorical_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "14/14 - 13s - loss: 1.0004 - categorical_accuracy: 0.5571 - val_loss: 1.2153 - val_categorical_accuracy: 0.5833\n",
            "Epoch 21/50\n",
            "14/14 - 13s - loss: 0.9743 - categorical_accuracy: 0.6084 - val_loss: 1.2455 - val_categorical_accuracy: 0.4792\n",
            "Epoch 22/50\n",
            "14/14 - 13s - loss: 0.9338 - categorical_accuracy: 0.6154 - val_loss: 1.3509 - val_categorical_accuracy: 0.4792\n",
            "Epoch 23/50\n",
            "14/14 - 13s - loss: 0.8795 - categorical_accuracy: 0.6527 - val_loss: 1.3830 - val_categorical_accuracy: 0.5208\n",
            "Epoch 24/50\n",
            "14/14 - 13s - loss: 0.8388 - categorical_accuracy: 0.6713 - val_loss: 1.3306 - val_categorical_accuracy: 0.4375\n",
            "Epoch 25/50\n",
            "14/14 - 13s - loss: 0.8601 - categorical_accuracy: 0.6270 - val_loss: 1.4181 - val_categorical_accuracy: 0.4583\n",
            "Epoch 26/50\n",
            "14/14 - 13s - loss: 0.7620 - categorical_accuracy: 0.7226 - val_loss: 1.4883 - val_categorical_accuracy: 0.5417\n",
            "Epoch 27/50\n",
            "14/14 - 13s - loss: 0.6836 - categorical_accuracy: 0.7249 - val_loss: 1.6149 - val_categorical_accuracy: 0.4583\n",
            "Epoch 28/50\n",
            "14/14 - 13s - loss: 0.5928 - categorical_accuracy: 0.7692 - val_loss: 1.6559 - val_categorical_accuracy: 0.4375\n",
            "Epoch 29/50\n",
            "14/14 - 13s - loss: 0.4816 - categorical_accuracy: 0.8392 - val_loss: 1.9404 - val_categorical_accuracy: 0.4583\n",
            "Epoch 30/50\n",
            "14/14 - 13s - loss: 0.5084 - categorical_accuracy: 0.7855 - val_loss: 1.7163 - val_categorical_accuracy: 0.4792\n",
            "Epoch 31/50\n",
            "14/14 - 13s - loss: 0.4544 - categorical_accuracy: 0.8462 - val_loss: 1.9890 - val_categorical_accuracy: 0.4167\n",
            "Epoch 32/50\n",
            "14/14 - 13s - loss: 0.3131 - categorical_accuracy: 0.8765 - val_loss: 3.4439 - val_categorical_accuracy: 0.4583\n",
            "Epoch 33/50\n",
            "14/14 - 13s - loss: 0.3331 - categorical_accuracy: 0.8765 - val_loss: 2.3256 - val_categorical_accuracy: 0.4792\n",
            "Epoch 34/50\n",
            "14/14 - 13s - loss: 0.2248 - categorical_accuracy: 0.9254 - val_loss: 2.7369 - val_categorical_accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "14/14 - 13s - loss: 0.2121 - categorical_accuracy: 0.9207 - val_loss: 2.9293 - val_categorical_accuracy: 0.5417\n",
            "Epoch 36/50\n",
            "14/14 - 13s - loss: 0.2166 - categorical_accuracy: 0.9021 - val_loss: 2.9064 - val_categorical_accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "14/14 - 13s - loss: 0.2167 - categorical_accuracy: 0.9254 - val_loss: 2.6157 - val_categorical_accuracy: 0.4167\n",
            "Epoch 38/50\n",
            "14/14 - 13s - loss: 0.1141 - categorical_accuracy: 0.9674 - val_loss: 3.6273 - val_categorical_accuracy: 0.4792\n",
            "Epoch 39/50\n",
            "14/14 - 13s - loss: 0.0906 - categorical_accuracy: 0.9650 - val_loss: 3.9956 - val_categorical_accuracy: 0.5208\n",
            "Epoch 40/50\n",
            "14/14 - 13s - loss: 0.0856 - categorical_accuracy: 0.9650 - val_loss: 4.1584 - val_categorical_accuracy: 0.4583\n",
            "Epoch 41/50\n",
            "14/14 - 13s - loss: 0.0844 - categorical_accuracy: 0.9744 - val_loss: 4.1067 - val_categorical_accuracy: 0.4792\n",
            "Epoch 42/50\n",
            "14/14 - 13s - loss: 0.0517 - categorical_accuracy: 0.9814 - val_loss: 5.1611 - val_categorical_accuracy: 0.4167\n",
            "Epoch 43/50\n",
            "14/14 - 13s - loss: 0.1394 - categorical_accuracy: 0.9371 - val_loss: 3.6919 - val_categorical_accuracy: 0.4792\n",
            "Epoch 44/50\n",
            "14/14 - 13s - loss: 0.2134 - categorical_accuracy: 0.9371 - val_loss: 3.2281 - val_categorical_accuracy: 0.4792\n",
            "Epoch 45/50\n",
            "14/14 - 13s - loss: 0.1287 - categorical_accuracy: 0.9697 - val_loss: 3.5186 - val_categorical_accuracy: 0.5208\n",
            "Epoch 46/50\n",
            "14/14 - 13s - loss: 0.0392 - categorical_accuracy: 0.9907 - val_loss: 4.4298 - val_categorical_accuracy: 0.4792\n",
            "Epoch 47/50\n",
            "14/14 - 13s - loss: 0.0160 - categorical_accuracy: 0.9953 - val_loss: 6.3668 - val_categorical_accuracy: 0.4792\n",
            "Epoch 48/50\n",
            "14/14 - 13s - loss: 0.0363 - categorical_accuracy: 0.9930 - val_loss: 5.0140 - val_categorical_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "14/14 - 13s - loss: 0.0452 - categorical_accuracy: 0.9837 - val_loss: 4.7191 - val_categorical_accuracy: 0.4375\n",
            "Epoch 50/50\n",
            "14/14 - 13s - loss: 0.0301 - categorical_accuracy: 0.9860 - val_loss: 5.3509 - val_categorical_accuracy: 0.4583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZWZSUwA7_wn",
        "outputId": "d7168522-4b35-4004-a94c-3a12a7704533"
      },
      "source": [
        "model_vgg_scratch.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 10s 3s/step - loss: 5.4445 - categorical_accuracy: 0.4500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.4445366859436035, 0.44999998807907104]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqEnADRO8UAv",
        "outputId": "783c8b67-00d6-46e6-98b4-ce189cf9cbef"
      },
      "source": [
        "pred = model_vgg_scratch.predict(x_test)\n",
        "pred = np.argmax(pred,axis=-1)\n",
        "true_labels = np.argmax(y_test,axis=-1)\n",
        "test_results = list(precision_recall_fscore_support(true_labels, pred, average = 'macro')[:-1])\n",
        "test_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3787426653805964, 0.3715555713810948, 0.3748103748103748]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUow-m0qo4W8"
      },
      "source": [
        "### Inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTZnB0yCezha"
      },
      "source": [
        "path_var = '/content/drive/MyDrive/project_data/' \n",
        "images = np.load(path_var + 'images_origin.npy')\n",
        "labels = np.load(path_var + 'labels.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i09efAKtqq0g"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(images, labels.astype(int), test_size=0.2, random_state=42, stratify=labels.astype(int))\n",
        "y_train = keras.utils.to_categorical(y_train, 4)\n",
        "y_test = keras.utils.to_categorical(y_test, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3VRBZGipFeg"
      },
      "source": [
        "def add_new_last_layer(base_model, nb_classes):\n",
        "  x = base_model.output\n",
        "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "  x = Dense(256, activation='relu')(x) #new FC layer, random init\n",
        "  predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
        "  model = Model(base_model.input, predictions)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0DpGEEopZZ2"
      },
      "source": [
        "def setup_to_transfer_learn(model, base_model):\n",
        "  \"\"\"Freeze all layers and compile the model\"\"\"\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRYQmrvhpeT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71203c3-e4f1-42c8-8833-a43528fb5f38"
      },
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False) \n",
        "model = add_new_last_layer(base_model, 4)              \n",
        "setup_to_transfer_learn(model, base_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XshTjP5Xqgye",
        "outputId": "4a8c4819-787a-4102-97b2-fb13704cc836"
      },
      "source": [
        "history_inception = model.fit(x_train, y_train, epochs=25, batch_size=4, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "108/108 [==============================] - 14s 76ms/step - loss: 1.8103 - accuracy: 0.4576 - val_loss: 1.0609 - val_accuracy: 0.5417\n",
            "Epoch 2/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.9532 - accuracy: 0.6311 - val_loss: 0.9377 - val_accuracy: 0.5417\n",
            "Epoch 3/25\n",
            "108/108 [==============================] - 6s 56ms/step - loss: 0.7117 - accuracy: 0.7123 - val_loss: 1.0878 - val_accuracy: 0.5417\n",
            "Epoch 4/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.5943 - accuracy: 0.7896 - val_loss: 0.9798 - val_accuracy: 0.6042\n",
            "Epoch 5/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.5564 - accuracy: 0.8102 - val_loss: 1.2816 - val_accuracy: 0.5417\n",
            "Epoch 6/25\n",
            "108/108 [==============================] - 6s 56ms/step - loss: 0.4781 - accuracy: 0.8049 - val_loss: 1.0453 - val_accuracy: 0.6042\n",
            "Epoch 7/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.3021 - accuracy: 0.9045 - val_loss: 1.6277 - val_accuracy: 0.5625\n",
            "Epoch 8/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.5166 - accuracy: 0.7957 - val_loss: 1.1287 - val_accuracy: 0.5833\n",
            "Epoch 9/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.2566 - accuracy: 0.9368 - val_loss: 1.3965 - val_accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.1729 - accuracy: 0.9628 - val_loss: 1.4316 - val_accuracy: 0.6250\n",
            "Epoch 11/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.1313 - accuracy: 0.9616 - val_loss: 1.2251 - val_accuracy: 0.6042\n",
            "Epoch 12/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.1989 - accuracy: 0.9394 - val_loss: 1.5790 - val_accuracy: 0.5625\n",
            "Epoch 13/25\n",
            "108/108 [==============================] - 6s 57ms/step - loss: 0.1066 - accuracy: 0.9702 - val_loss: 1.4845 - val_accuracy: 0.5625\n",
            "Epoch 14/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.1752 - accuracy: 0.9376 - val_loss: 1.8311 - val_accuracy: 0.5625\n",
            "Epoch 15/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0877 - accuracy: 0.9940 - val_loss: 1.6704 - val_accuracy: 0.5833\n",
            "Epoch 16/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0788 - accuracy: 0.9735 - val_loss: 1.5924 - val_accuracy: 0.6250\n",
            "Epoch 17/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.7070 - val_accuracy: 0.5417\n",
            "Epoch 18/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0222 - accuracy: 0.9992 - val_loss: 1.5819 - val_accuracy: 0.6042\n",
            "Epoch 19/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0250 - accuracy: 0.9979 - val_loss: 1.6403 - val_accuracy: 0.5208\n",
            "Epoch 20/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.7318 - val_accuracy: 0.5208\n",
            "Epoch 21/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.8882 - val_accuracy: 0.5000\n",
            "Epoch 22/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.7574 - val_accuracy: 0.5208\n",
            "Epoch 23/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.8569 - val_accuracy: 0.6042\n",
            "Epoch 24/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.9077 - val_accuracy: 0.5208\n",
            "Epoch 25/25\n",
            "108/108 [==============================] - 6s 58ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.8228 - val_accuracy: 0.5208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYS1qTMZ_SfC",
        "outputId": "6d180b46-c021-4705-e0ba-7e76f78f60f4"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 6s 782ms/step - loss: 1.5983 - accuracy: 0.6583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5982508659362793, 0.6583333611488342]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4AmXp5J_lVI",
        "outputId": "4bca7581-cfd8-4d4d-80b7-752172bc9d47"
      },
      "source": [
        "pred_in = model.predict(x_test)\n",
        "pred_in = np.argmax(pred_in,axis=-1)\n",
        "true_labels = np.argmax(y_test,axis=-1)\n",
        "test_results = list(precision_recall_fscore_support(true_labels, pred_in, average = 'macro')[:-1])\n",
        "test_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6071694006476616, 0.6134394435740398, 0.6065628035445868]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5_K7zwdwJs8"
      },
      "source": [
        "def setup_to_finetune(model):\n",
        "  for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
        "     layer.trainable = False\n",
        "  for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
        "     layer.trainable = True\n",
        "  model.compile(keras.optimizers.SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhO5X5BOwwuE"
      },
      "source": [
        "NB_IV3_LAYERS_TO_FREEZE = 172\n",
        "#base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "model_ince2 = add_new_last_layer(base_model, 4)             \n",
        "setup_to_finetune(model_ince2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhOra2sSxvfb",
        "outputId": "12bdd4b2-14c2-4a8b-c498-3e5c7fcbf1a7"
      },
      "source": [
        "history_inception2 = model_ince2.fit(x_train, y_train, epochs=25, batch_size=4, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "108/108 [==============================] - 11s 54ms/step - loss: 1.3373 - accuracy: 0.3829 - val_loss: 1.2531 - val_accuracy: 0.4167\n",
            "Epoch 2/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 1.1602 - accuracy: 0.4693 - val_loss: 1.2477 - val_accuracy: 0.4375\n",
            "Epoch 3/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 1.0361 - accuracy: 0.5895 - val_loss: 1.2152 - val_accuracy: 0.4375\n",
            "Epoch 4/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.9109 - accuracy: 0.6075 - val_loss: 1.1403 - val_accuracy: 0.4167\n",
            "Epoch 5/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.8299 - accuracy: 0.6838 - val_loss: 1.1221 - val_accuracy: 0.4375\n",
            "Epoch 6/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.7555 - accuracy: 0.7335 - val_loss: 1.0815 - val_accuracy: 0.4167\n",
            "Epoch 7/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.6756 - accuracy: 0.8060 - val_loss: 1.0516 - val_accuracy: 0.5208\n",
            "Epoch 8/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.6115 - accuracy: 0.7939 - val_loss: 1.0347 - val_accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.5715 - accuracy: 0.8268 - val_loss: 1.0358 - val_accuracy: 0.4583\n",
            "Epoch 10/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.5029 - accuracy: 0.8677 - val_loss: 1.0316 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.3646 - accuracy: 0.9160 - val_loss: 1.0193 - val_accuracy: 0.4375\n",
            "Epoch 12/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.4102 - accuracy: 0.9093 - val_loss: 1.0158 - val_accuracy: 0.5000\n",
            "Epoch 13/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.2987 - accuracy: 0.9266 - val_loss: 1.0092 - val_accuracy: 0.4583\n",
            "Epoch 14/25\n",
            "108/108 [==============================] - 4s 39ms/step - loss: 0.2398 - accuracy: 0.9536 - val_loss: 1.0796 - val_accuracy: 0.5000\n",
            "Epoch 15/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.2675 - accuracy: 0.9288 - val_loss: 1.0795 - val_accuracy: 0.5000\n",
            "Epoch 16/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.2767 - accuracy: 0.9283 - val_loss: 1.0514 - val_accuracy: 0.5000\n",
            "Epoch 17/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.1758 - accuracy: 0.9712 - val_loss: 1.0389 - val_accuracy: 0.5417\n",
            "Epoch 18/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.1968 - accuracy: 0.9669 - val_loss: 1.0769 - val_accuracy: 0.5625\n",
            "Epoch 19/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.1424 - accuracy: 0.9905 - val_loss: 1.0184 - val_accuracy: 0.5417\n",
            "Epoch 20/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.1391 - accuracy: 0.9791 - val_loss: 1.0581 - val_accuracy: 0.5625\n",
            "Epoch 21/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.1556 - accuracy: 0.9568 - val_loss: 1.0923 - val_accuracy: 0.5208\n",
            "Epoch 22/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.1751 - accuracy: 0.9455 - val_loss: 1.0888 - val_accuracy: 0.5833\n",
            "Epoch 23/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.1206 - accuracy: 0.9702 - val_loss: 1.0645 - val_accuracy: 0.5833\n",
            "Epoch 24/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.1160 - accuracy: 0.9712 - val_loss: 1.1063 - val_accuracy: 0.5208\n",
            "Epoch 25/25\n",
            "108/108 [==============================] - 4s 40ms/step - loss: 0.2756 - accuracy: 0.9107 - val_loss: 1.1035 - val_accuracy: 0.5417\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}